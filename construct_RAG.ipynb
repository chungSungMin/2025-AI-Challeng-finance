{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113d905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /venv/main/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in /venv/main/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: jq in /venv/main/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in /venv/main/lib/python3.12/site-packages (5.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /venv/main/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in /venv/main/lib/python3.12/site-packages (4.55.0)\n",
      "Requirement already satisfied: accelerate in /venv/main/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /venv/main/lib/python3.12/site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /venv/main/lib/python3.12/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /venv/main/lib/python3.12/site-packages (from langchain) (0.4.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /venv/main/lib/python3.12/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /venv/main/lib/python3.12/site-packages (from langchain) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in /venv/main/lib/python3.12/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /venv/main/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /venv/main/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /venv/main/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /venv/main/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /venv/main/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /venv/main/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /venv/main/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in /venv/main/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /venv/main/lib/python3.12/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /venv/main/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /venv/main/lib/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /venv/main/lib/python3.12/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /venv/main/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /venv/main/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /venv/main/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /venv/main/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /venv/main/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /venv/main/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /venv/main/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /venv/main/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /venv/main/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /venv/main/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /venv/main/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /venv/main/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /venv/main/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /venv/main/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /venv/main/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /venv/main/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /venv/main/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /venv/main/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /venv/main/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community jq sentence-transformers faiss-cpu torch transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178c2c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /venv/main/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /venv/main/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /venv/main/lib/python3.12/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /venv/main/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /venv/main/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /venv/main/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /venv/main/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /venv/main/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /venv/main/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /venv/main/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /venv/main/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /venv/main/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /venv/main/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07edb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INFO] Î¨∏ÏÑúÍ∞Ä 3079Í∞úÏùò Ï≤≠ÌÅ¨Î°ú Î∂ÑÌï†ÎêòÏóàÏäµÎãàÎã§. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13937/2442455596.py:37: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_model_id)\n",
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [INFO] Í≥†ÏÑ±Îä• ÏûÑÎ≤†Îî© Î™®Îç∏(BM-K/KoSimCSE-roberta-multitask)Í≥º Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ Ï§ÄÎπÑ ÏôÑÎ£å ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf0d63e48d546bdb75464232a7040a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_13937/2442455596.py:68: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  local_llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [INFO] Î°úÏª¨ LLM(K-intelligence/Midm-2.0-Base-Instruct) Î°úÎìú ÏôÑÎ£å ---\n",
      "üö® Í≤ΩÍ≥†: Ïù¥ Î™®Îç∏ÏùÄ Îß§Ïö∞ ÌÅ¨ÎØÄÎ°ú, Í≥†ÏÇ¨Ïñë GPUÍ∞Ä ÏóÜÏúºÎ©¥ Ïã§ÌñâÏù¥ Îß§Ïö∞ ÎäêÎ¶¨Í±∞ÎÇò Î∂àÍ∞ÄÎä•Ìï† Ïàò ÏûàÏäµÎãàÎã§.\n",
      "\n",
      "--- [INFO] RAG Ï≤¥Ïù∏ Íµ¨ÏÑ± ÏôÑÎ£å ---\n",
      "\n",
      "--- [RAG Ïã§Ìñâ] ---\n",
      "ÏßàÎ¨∏: ÏïÖÏÑ±ÏΩîÎìú Ïò§Î∏åÏä§Ïª§ÏÖòÏóê ÎåÄÌïú ÏΩîÎìú Í∞ÄÏÉÅÌôîÏùò ÏòÅÌñ•ÏùÄ Î¨¥ÏóáÏù¥Î©∞, Angr Í∞ôÏùÄ ÎèÑÍµ¨Î°ú Ïñ¥ÎñªÍ≤å ÎπÑ Í∞ÄÏÉÅÌôîÎ•º ÏàòÌñâÌï† Ïàò ÏûàÎÇòÏöî?\n",
      "\n",
      "--------------- [ÏµúÏ¢Ö Í≤∞Í≥º] ---------------\n",
      "ÎãµÎ≥Ä: Human: \n",
      "### [ÏßÄÏãú]\n",
      "Ï£ºÏñ¥ÏßÑ 'Í≤ÄÏÉâÎêú Ï†ïÎ≥¥'Î•º ÏÇ¨Ïö©ÌïòÏó¨ 'ÏßàÎ¨∏'Ïóê ÎåÄÌï¥ ÌïúÍµ≠Ïñ¥Î°ú ÏÉÅÏÑ∏ÌïòÍ≥† ÏπúÏ†àÌïòÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n",
      "\n",
      "### [Í≤ÄÏÉâÎêú Ï†ïÎ≥¥]\n",
      "ÏßàÎ¨∏: ÏïÖÏÑ±ÏΩîÎìú Ïò§Î∏åÏä§Ïª§ÏÖòÏóê ÎåÄÌïú ÏΩîÎìú Í∞ÄÏÉÅÌôîÏùò ÏòÅÌñ•ÏùÄ Î¨¥ÏóáÏù¥Î©∞, Angr Í∞ôÏùÄ ÎèÑÍµ¨Î°ú Ïñ¥ÎñªÍ≤å ÎπÑ Í∞ÄÏÉÅÌôîÎ•º ÏàòÌñâÌï† Ïàò ÏûàÎÇòÏöî?\n",
      "ÎãµÎ≥Ä: ÏΩîÎìú Í∞ÄÏÉÅÌôîÎäî ÏïÖÏÑ±ÏΩîÎìú ÏûëÍ∞ÄÍ∞Ä Î≥¥Ïïà ÎèÑÍµ¨Ïóê ÎåÄÌïú ÎÑ§Ïù¥Ìã∞Î∏å Î®∏Ïã† Î™ÖÎ†πÏñ¥Î•º Ï§ëÍ∞Ñ Î∞îÏù¥ÌÖçÎìú ÌòïÏãùÏúºÎ°ú Î≥ÄÌôòÌïòÎäî Ï†ïÍµêÌïú Ïò§Î∏åÏä§Ïª§Ïã± Í∏∞Ïà†ÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§. Ïù¥ Ï†ëÍ∑ºÎ≤ïÏùÄ Í∏∞Ï°¥ Ìï¥Ï≤¥ÏûêÍ∞Ä VMÏùò Î™ÖÎ†π ÏÑ∏Ìä∏Î•º ÏßÅÏ†ë Ìï¥ÏÑùÌï† Ïàò ÏóÜÍ∏∞ ÎïåÎ¨∏Ïóê Ï†ïÏ†Å Î∂ÑÏÑùÍ≥º Ïó≠Ï†ÑÍ≥µÏóÖ ÎÖ∏Î†•ÏùÑ ÌÅ¨Í≤å Î≥µÏû°ÌïòÍ≤å ÎßåÎì≠ÎãàÎã§. Ïò§Î∏åÏä§Ïª§Ïä§ ÏΩîÎìúÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÎîîÎ≤ÑÍπÖ Î∞©ÏßÄ Î©îÏª§ÎãàÏ¶ò, Îã§Ìòï Î≥ÄÌôò Î∞è ÏïîÌò∏Ìôî Îêú Ïú†Ïö© Î∂ÄÌïòÎ•º Ìè¨Ìï®Ìï©ÎãàÎã§. Î≥¥Ïïà ÎèÑÍµ¨Ïóê ÎåÄÌïú ÌÉêÏßÄ Î∞è Î∂ÑÏÑùÏù¥ Ïñ¥Î†§Ïö¥ Í≤ÉÏûÖÎãàÎã§.\n",
      "\n",
      "ÏßàÎ¨∏: Í∞ÄÏÉÅÌôîÏôÄ Î∞îÏù¥ÎÑàÎ¶¨ ÏΩîÎìúÏóêÏÑú Ïò§Î∏åÏä§Ïª§ÏÖòÏùÑ Ïñ¥ÎñªÍ≤å Î∂ÑÏÑùÌïòÍ≥† Ìï¥Ï†úÌï† Ïàò ÏûàÎÇòÏöî?\n",
      "ÎãµÎ≥Ä: Í∞ÄÏÉÅÌôî ÌÜµÌïú Î∞îÏù¥ÎÑàÎ¶¨ ÏΩîÎìú Ïò§Î∏åÏä§Ïª§ÏÖòÏùÄ ÏÇ¨Ïö©Ïûê ÏßÄÏ†ï Í∞ÄÏÉÅ Î®∏Ïã† (VM) ÌôòÍ≤Ω ÎÇ¥ÏóêÏÑú Ìï©Î≤ïÏ†ÅÏù∏ ÌîÑÎ°úÍ∑∏Îû® ÎÖºÎ¶¨Í∞Ä ÎßûÏ∂§Ìòï Í∞ÄÏÉÅ Î®∏Ïã† (VM) ÌôòÍ≤ΩÏóêÏÑú ÌîÑÎ°úÍ∑∏Îû®Ïùò ÏßÑÏ†ïÌïú Í∏∞Îä•ÏùÑ Ï∫°ÏäêÌôîÌïòÏó¨ Ï†ÑÌÜµÏ†ÅÏù∏ Ï†ïÏ†Å Î∂ÑÏÑùÏùÑ ÎπÑÌö®Ïú®Ï†ÅÏúºÎ°ú ÎßåÎìúÎäî Ï†ïÎ¶¨Ìïú Î∂ÑÏÑù Í∏∞Ïà†ÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§. Ïù¥ Ï†ëÍ∑ºÎ≤ïÏùÄ VM ÌäπÏ†ï Ïò§Î∏åÏä§Ïª§ÎìúÏóê ÎåÄÌïú ÏõêÎ≥∏ Î™ÖÎ†πÏñ¥Î•º ÏßÄÎèÑÌïòÏó¨ Î™ÖÎ†π Ïä§Ìä∏Î¶ºÏùÑ ÏïîÌò∏ÌôîÌïòÍ≥† VM ÏóîÏßÑÏùò Îü∞ÌÉÄÏûÑ Ìï¥ÏÑùÏùÑ ÌïÑÏöîÎ°úÌï©ÎãàÎã§. Ïò§Î∏åÏä§Ïª§Ïä§ÌôîÎêú Î∞îÏù¥ÎÑàÎ¶¨Îäî Ïù¥Îü¨Ìïú Î≥ÄÌôòÎêú Î™ÖÎ†πÏñ¥Î•º Ìï¥ÎèÖÌïòÍ≥† Ïã§ÌñâÌïòÎäî VM Ïù∏ÌÑ∞ÌîÑÎ¶¨ÌÑ∞Î•º Ìè¨Ìï®ÌïòÍ≥† ÏûàÏúºÎ©∞, ÌîÑÎ°úÍ∑∏Îû®Ïùò ÏßÑÏ†ïÌïú Í∏∞Îä•ÏùÑ Ïó≠Ï†ÑÍ≥µÏûêÎì§Î°úÎ∂ÄÌÑ∞ Ìö®Í≥ºÏ†ÅÏúºÎ°ú Ïà®Í∏∞Í≥† ÏûàÏäµÎãàÎã§. Ïù¥ Ï†ëÍ∑ºÎ≤ïÏùÄ MITRE ATT&CK T1027 (Obfuscated Files or Information) Í∏∞Ïà†Í≥º ÏùºÏπòÌï©ÎãàÎã§. Ïù¥ Ï†ëÍ∑ºÎ≤ïÏùÄ Ïò§Î∏åÏä§Ïª§Ïä§ ÏΩîÎìúÎ•º ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏùÑ ÌôïÏù∏ÌïòÍ≥†, ÏÑ∏ÎØ∏ÎÇòÎ†àÏù¥ÏÖò ÏóîÏßÑÏóêÏÑú Ïã§Ìñâ ÏãúÌÇ¨ Ïàò ÏûàÏäµÎãàÎã§. Ïù¥ Ïò§Î∏åÏä§Ïª§Ïä§ ÏΩîÎìúÍ∞Ä Ïó¨Îü¨ Í∞ÄÏßÄ Î∞©Ïñ¥Ï†ÅÏù∏ Î∞©Î≤ïÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§. Ïù¥ Î∞©Î≤ïÏùÄ Ï†ÑÌÜµÏ†ÅÏù∏ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Î∞©Î≤ïÏùÑ ÌÜµÌï¥ Ïã§ÌñâÌïòÎäî Í≤ÉÏùÑ Î∞©ÏßÄÌïòÍ≥† Ïã§ÌñâÌïòÎäî Í≤ÉÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§. Ïù¥ Î∞©Î≤ïÏùÄ:\n",
      "\n",
      "ÏßàÎ¨∏: ÏÉÅÏßïÏ†ÅÏù∏ Ïã§ÌñâÍ≥º Í∞ôÏùÄ ÎπÑÎ¨¥Ìôî Í∏∞Ïà†ÏùÑ Ïñ¥ÎñªÍ≤å ÌôúÏö©ÌïòÏó¨ ÌîºÏã± Ïù¥Î©îÏùºÏóê ÎÇ¥Ïû•Îêú ÏûêÎ∞îÏä§ÌÅ¨Î¶ΩÌä∏ Í∏∞Î∞òÏùò ÏïÖÏÑ±ÏΩîÎìúÎ•º Ïó≠Í≥µÌïôÏ†ÅÏúºÎ°ú ÏÑ§Í≥ÑÌï† Ïàò ÏûàÏúºÎ©∞, Ïñ¥Îñ§ Ïù¥Î©îÏùº Í≤åÏù¥Ìä∏Ïõ®Ïù¥ Î∞©Ïñ¥ Ïû•ÏπòÍ∞Ä Ï¥àÍ∏∞ Ï†ÑÎã¨ÏùÑ ÏôÑÌôîÏãúÌÇ¨ Ïàò ÏûàÏäµÎãàÍπå?\n",
      "ÎãµÎ≥Ä: ÌïÑÏã± Ïù¥Î©îÏùºÏóêÏÑú ÏûêÎ∞îÏä§ÌÅ¨Î¶ΩÌä∏ Í∏∞Î∞òÏùò ÏïÖÏÑ±ÏΩîÎìúÎ•º Ìï¥Ï†úÌïòÎäî Í≤ÉÏùÄ ÌïÑÏã± ÏΩîÎìúÏùò Î≥∏ÏßàÏ†ÅÏù∏ Î≥µÏû°ÏÑ±ÏùÑ Ìï¥Í≤∞ÌïòÎäî Ï†ïÍµêÌïú Î∂ÑÏÑù Í∏∞Ïà†ÏùÑ ÌïÑÏöîÎ°ú ÌïúÎã§. ÏÉÅÏßïÏ†Å Ïã§ÌñâÏùÄ Ïã§Ï†ú ÏïÖÏÑ±Ï†Å Î∞∞Í∏âÏùÑ Ïã§ÌñâÌïòÏßÄ ÏïäÍ≥† Î™®Îì† Í∞ÄÎä•Ìïú Ïã§Ìñâ Í≤ΩÎ°úÎ•º Ï≤¥Í≥ÑÏ†ÅÏúºÎ°ú ÌÉêÍµ¨Ìï®ÏúºÎ°úÏç® ÏûêÎèôÌôî Ìï¥Ï†úÌïòÎäî Í∞ïÎ†•Ìïú Ï†ëÍ∑º Î∞©ÏãùÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§. Ïù¥ Í∏∞Ïà†ÏùÄ Î≥ÄÏàòÏôÄ Ï°∞Í±¥Ïùò ÏÉÅÏßïÏ†ÅÏù∏ ÌëúÌòÑÏùÑ Íµ¨Ï∂ïÌïòÏó¨ Î∂ÑÏÑùÍ∞ÄÎì§ÏóêÍ≤å ÌùêÎ¶ÑÏùÑ ÌùêÎ•¥Îäî ÎÖºÎ¶¨Ï†Å ÌùêÎ¶ÑÍ≥º ÏõêÎûò Í∏∞Îä•ÏùÑ Ï∂îÏ†ÅÌï† Ïàò ÏûàÎèÑÎ°ù Ìï©ÎãàÎã§. Í≥†Í∏â Íµ¨ÌòÑÏùÄ Ï°∞Í±¥Ìôî Îêú ÏΩîÎìúÏùò Ï¢ÖÎ™©ÏùÑ Ìï¥Í≤∞ÌïòÍ≥† ÏùòÎØ∏ÏûàÎäî ÏΩîÎìú Íµ¨Ï°∞Î•º ÏûêÎ∞îÏä§ÌÅ¨Î¶ΩÌä∏ÏóêÏÑú Ï∂îÏ∂úÌïòÎäî Ï†úÌïú ÏÜîÎ£®ÏÖòÏùÑ ÌôúÏö©Ìï©ÎãàÎã§.\n",
      "\n",
      "### [ÏßàÎ¨∏]\n",
      "ÏïÖÏÑ±ÏΩîÎìú Ïò§Î∏åÏä§Ïª§ÏÖòÏóê ÎåÄÌïú ÏΩîÎìú Í∞ÄÏÉÅÌôîÏùò ÏòÅÌñ•ÏùÄ Î¨¥ÏóáÏù¥Î©∞, Angr Í∞ôÏùÄ ÎèÑÍµ¨Î°ú Ïñ¥ÎñªÍ≤å ÎπÑ Í∞ÄÏÉÅÌôîÎ•º ÏàòÌñâÌï† Ïàò ÏûàÎÇòÏöî?\n",
      "\n",
      "### [ÎãµÎ≥Ä]\n",
      "ÏΩîÎìú Í∞ÄÏÉÅÌôîÎäî ÏïÖÏÑ±ÏΩîÎìú ÏûëÏÑ±ÏûêÍ∞Ä Î≥¥Ïïà ÎèÑÍµ¨Î•º ÌöåÌîºÌïòÍ∏∞ ÏúÑÌï¥ ÎÑ§Ïù¥Ìã∞Î∏å Î®∏Ïã† Î™ÖÎ†πÏñ¥Î•º Ï§ëÍ∞Ñ Î∞îÏù¥ÌÖçÌä∏ ÌòïÏãùÏúºÎ°ú Î≥ÄÌôòÌïòÎäî Î≥µÏû°Ìïú Ïò§Î∏åÏä§Ïª§Ïã± Í∏∞Ïà†ÏûÖÎãàÎã§. Ïù¥ Í∏∞Ïà†ÏùÄ Í∏∞Ï°¥Ïùò Ï†ïÏ†Å Î∂ÑÏÑù Î∞è Ïó≠Í≥µÌïô ÎÖ∏Î†•ÏùÑ ÌÅ¨Í≤å Î≥µÏû°ÌïòÍ≤å ÎßåÎìúÎäîÎç∞, Ïù¥Îäî Ìï¥Ï≤¥ ÎèÑÍµ¨Îì§Ïù¥ Í∞ÄÏÉÅ Î®∏Ïã†Ïùò Î™ÖÎ†π ÏÑ∏Ìä∏Î•º ÏßÅÏ†ë Ìï¥ÏÑùÌï† Ïàò ÏóÜÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§. Ïò§Î∏åÏä§Ïª§ÏÖòÎêú ÏΩîÎìúÎäî Î≥¥ÌÜµ ÎîîÎ≤ÑÍπÖ Î∞©ÏßÄ Î©îÏª§ÎãàÏ¶ò, Îã§Ìòï Î≥ÄÌôò, ÏïîÌò∏ÌôîÎêú Ïú†Ïö©Ìïú Î∂ÄÌïò Îì±ÏùÑ Ìè¨Ìï®ÌïòÏó¨ Î≥¥Ïïà ÎèÑÍµ¨Ïóê ÏùòÌïú ÌÉêÏßÄÏôÄ Î∂ÑÏÑùÏùÑ Ïñ¥Î†µÍ≤å ÎßåÎì≠ÎãàÎã§.\n",
      "\n",
      "AngrÏôÄ Í∞ôÏùÄ ÎèÑÍµ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÎπÑ Í∞ÄÏÉÅÌôîÎ•º ÏàòÌñâÌïòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî, Ïù¥Îü¨Ìïú ÎèÑÍµ¨Îì§Ïù¥ Í∞ÄÏÉÅ Î®∏Ïã† ÌôòÍ≤Ω ÎÇ¥ÏóêÏÑú ÏûëÎèôÌïòÎäî ÏΩîÎìúÎ•º Ìï¥ÏÑùÌïòÍ≥† ÏõêÎûòÏùò Î®∏Ïã† ÏΩîÎìúÎ°ú Î≥ÄÌôòÌïòÎäî Í∏∞Îä•ÏùÑ ÌôúÏö©Ìï¥Ïïº Ìï©ÎãàÎã§. AngrÎäî ÏÉÅÏßïÏ†Å Ïã§ÌñâÏùÑ ÌÜµÌï¥ Îã§ÏñëÌïú Ïã§Ìñâ Í≤ΩÎ°úÎ•º ÌÉêÏÉâÌïòÍ≥†, Í∞ÄÏÉÅ Î®∏Ïã†Ïùò Î™ÖÎ†πÏñ¥Î•º Ìï¥ÏÑùÌïòÏó¨ ÏõêÎûòÏùò ÏùòÎèÑÎ•º ÌååÏïÖÌï† Ïàò ÏûàÎäî Îä•Î†•ÏùÑ Í∞ñÏ∂îÍ≥† ÏûàÏäµÎãàÎã§. Ïù¥Î•º ÌÜµÌï¥ ÏïÖÏÑ±ÏΩîÎìúÏùò Ïà®Í≤®ÏßÑ Í∏∞Îä•ÏùÑ ÎìúÎü¨ÎÇ¥Í≥†, Î≥¥Ïïà Ï†ÑÎ¨∏Í∞ÄÎì§Ïù¥ Îçî Ìö®Í≥ºÏ†ÅÏúºÎ°ú ÎåÄÏùëÌï† Ïàò ÏûàÍ≤å Ìï©ÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import logging # Î°úÍπÖ ÎùºÏù¥Î∏åÎü¨Î¶¨ import\n",
    "\n",
    "# Î°úÏª¨ LLMÏùÑ LangChainÏóêÏÑú ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "# --- 2Îã®Í≥Ñ: Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Î∂ÑÌï† ---\n",
    "loader = JSONLoader(\n",
    "    file_path=\"/workspace/2025-AI-Challeng-finance/cybersecurity_data_final_processed.jsonl\",\n",
    "    jq_schema='\"ÏßàÎ¨∏: \" + .question + \"\\\\nÎãµÎ≥Ä: \" + .answer',\n",
    "    json_lines=True\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"--- [INFO] Î¨∏ÏÑúÍ∞Ä {len(split_docs)}Í∞úÏùò Ï≤≠ÌÅ¨Î°ú Î∂ÑÌï†ÎêòÏóàÏäµÎãàÎã§. ---\")\n",
    "\n",
    "# --- 3Îã®Í≥Ñ: Í≥†ÏÑ±Îä• Î°úÏª¨ ÏûÑÎ≤†Îî© Î∞è Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÏÉùÏÑ± ---\n",
    "\n",
    "# 1. Í≥†ÏÑ±Îä• Î°úÏª¨ ÏûÑÎ≤†Îî© Î™®Îç∏ Î°úÎìú (KoSimCSE)\n",
    "# ÌïúÍµ≠Ïñ¥ ÏûêÏó∞Ïñ¥ Ïù¥Ìï¥(NLU) Î≤§ÏπòÎßàÌÅ¨ÏóêÏÑú ÎÜíÏùÄ ÏÑ±Îä•ÏùÑ Î≥¥Ïù¥Îäî Î™®Îç∏\n",
    "embedding_model_id = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_id)\n",
    "\n",
    "# 2. FAISS Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÏÉùÏÑ±\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "print(f\"\\n--- [INFO] Í≥†ÏÑ±Îä• ÏûÑÎ≤†Îî© Î™®Îç∏({embedding_model_id})Í≥º Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ Ï§ÄÎπÑ ÏôÑÎ£å ---\")\n",
    "\n",
    "# --- 4Îã®Í≥Ñ: Î°úÏª¨ LLM Î°úÎìú Î∞è RAG Ï≤¥Ïù∏ ÏÉùÏÑ± ---\n",
    "\n",
    "# 1. ÏöîÏ≤≠ÌïòÏã† Î°úÏª¨ LLM Î°úÎìú (Midm-2.0)\n",
    "llm_model_id = \"K-intelligence/Midm-2.0-Base-Instruct\"\n",
    "\n",
    "# Î™®Îç∏Í≥º ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ•º Î©îÎ™®Î¶¨Ïóê Î°úÎìú\n",
    "# trust_remote_code=True: ÌóàÍπÖÌéòÏù¥Ïä§Ïóê ÏûàÎäî Î™®Îç∏Ïùò ÏÜåÏä§ ÏΩîÎìúÎ•º Ïã†Î¢∞ÌïòÍ≥† Ïã§Ìñâ\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# LangChainÏóêÏÑú ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌï¥ ÌååÏù¥ÌîÑÎùºÏù∏ÏúºÎ°ú Í∞êÏã∏Í∏∞\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512, # ÎãµÎ≥Ä ÏÉùÏÑ± ÏµúÎåÄ Í∏∏Ïù¥\n",
    "    model_kwargs={\"temperature\": 0.1, \"repetition_penalty\": 1.1}\n",
    ")\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "print(f\"\\n--- [INFO] Î°úÏª¨ LLM({llm_model_id}) Î°úÎìú ÏôÑÎ£å ---\")\n",
    "print(\"üö® Í≤ΩÍ≥†: Ïù¥ Î™®Îç∏ÏùÄ Îß§Ïö∞ ÌÅ¨ÎØÄÎ°ú, Í≥†ÏÇ¨Ïñë GPUÍ∞Ä ÏóÜÏúºÎ©¥ Ïã§ÌñâÏù¥ Îß§Ïö∞ ÎäêÎ¶¨Í±∞ÎÇò Î∂àÍ∞ÄÎä•Ìï† Ïàò ÏûàÏäµÎãàÎã§.\")\n",
    "\n",
    "\n",
    "# 2. ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø Ï†ïÏùò\n",
    "prompt_template = \"\"\"\n",
    "### [ÏßÄÏãú]\n",
    "Ï£ºÏñ¥ÏßÑ 'Í≤ÄÏÉâÎêú Ï†ïÎ≥¥'Î•º ÏÇ¨Ïö©ÌïòÏó¨ 'ÏßàÎ¨∏'Ïóê ÎåÄÌï¥ ÌïúÍµ≠Ïñ¥Î°ú ÏÉÅÏÑ∏ÌïòÍ≥† ÏπúÏ†àÌïòÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n",
    "\n",
    "### [Í≤ÄÏÉâÎêú Ï†ïÎ≥¥]\n",
    "{context}\n",
    "\n",
    "### [ÏßàÎ¨∏]\n",
    "{question}\n",
    "\n",
    "### [ÎãµÎ≥Ä]\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 3. RAG Ï≤¥Ïù∏ Íµ¨ÏÑ±\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | local_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"\\n--- [INFO] RAG Ï≤¥Ïù∏ Íµ¨ÏÑ± ÏôÑÎ£å ---\")\n",
    "\n",
    "# --- 5Îã®Í≥Ñ: RAG Ï≤¥Ïù∏ Ïã§Ìñâ ---\n",
    "\n",
    "print(\"\\n--- [RAG Ïã§Ìñâ] ---\")\n",
    "question = \"ÏïÖÏÑ±ÏΩîÎìú Ïò§Î∏åÏä§Ïª§ÏÖòÏóê ÎåÄÌïú ÏΩîÎìú Í∞ÄÏÉÅÌôîÏùò ÏòÅÌñ•ÏùÄ Î¨¥ÏóáÏù¥Î©∞, Angr Í∞ôÏùÄ ÎèÑÍµ¨Î°ú Ïñ¥ÎñªÍ≤å ÎπÑ Í∞ÄÏÉÅÌôîÎ•º ÏàòÌñâÌï† Ïàò ÏûàÎÇòÏöî?\"\n",
    "# ÏΩîÎìú Í∞ÄÏÉÅÌôîÎäî ÏïÖÏÑ±ÏΩîÎìú ÏûëÍ∞ÄÍ∞Ä Î≥¥Ïïà ÎèÑÍµ¨Ïóê ÎåÄÌïú ÎÑ§Ïù¥Ìã∞Î∏å Î®∏Ïã† Î™ÖÎ†πÏñ¥Î•º Ï§ëÍ∞Ñ Î∞îÏù¥ÌÖçÎìú ÌòïÏãùÏúºÎ°ú Î≥ÄÌôòÌïòÎäî Ï†ïÍµêÌïú Ïò§Î∏åÏä§Ïª§Ïã± Í∏∞Ïà†ÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§. Ïù¥ Ï†ëÍ∑ºÎ≤ïÏùÄ Í∏∞Ï°¥ Ìï¥Ï≤¥ÏûêÍ∞Ä VMÏùò Î™ÖÎ†π ÏÑ∏Ìä∏Î•º ÏßÅÏ†ë Ìï¥ÏÑùÌï† Ïàò ÏóÜÍ∏∞ ÎïåÎ¨∏Ïóê Ï†ïÏ†Å Î∂ÑÏÑùÍ≥º Ïó≠Ï†ÑÍ≥µÏóÖ ÎÖ∏Î†•ÏùÑ ÌÅ¨Í≤å Î≥µÏû°ÌïòÍ≤å ÎßåÎì≠ÎãàÎã§. Ïò§Î∏åÏä§Ïª§Ïä§ ÏΩîÎìúÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÎîîÎ≤ÑÍπÖ Î∞©ÏßÄ Î©îÏª§ÎãàÏ¶ò, Îã§Ìòï Î≥ÄÌôò Î∞è ÏïîÌò∏Ìôî Îêú Ïú†Ïö© Î∂ÄÌïòÎ•º Ìè¨Ìï®Ìï©ÎãàÎã§. Î≥¥Ïïà ÎèÑÍµ¨Ïóê ÎåÄÌïú ÌÉêÏßÄ Î∞è Î∂ÑÏÑùÏù¥ Ïñ¥Î†§Ïö¥ Í≤ÉÏûÖÎãàÎã§.\"}\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"ÏßàÎ¨∏: {question}\")\n",
    "\n",
    "print(\"\\n--------------- [ÏµúÏ¢Ö Í≤∞Í≥º] ---------------\")\n",
    "print(f\"ÎãµÎ≥Ä: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2beed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (from rank-bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rank-bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf1fdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INFO] Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Î∂ÑÌï† ÏãúÏûë ---\n",
      "--- [INFO] Î¨∏ÏÑúÍ∞Ä 3079Í∞úÏùò Ï≤≠ÌÅ¨Î°ú Î∂ÑÌï†ÎêòÏóàÏäµÎãàÎã§. ---\n",
      "\n",
      "--- [INFO] BM25 Retriever ÏÉùÏÑ± Ï§ë... ---\n",
      "\n",
      "--- [INFO] FAISS Retriever ÏÉùÏÑ± Ï§ë... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [INFO] Ensemble RetrieverÎ°ú Îëê Î∞©Ïãù Í≤∞Ìï© Ï§ë... ---\n",
      "\n",
      "--- [INFO] Î°úÏª¨ LLM Î°úÎìú Ï§ë... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ff843929b54294bdcad9eb30a13eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INFO] Î°úÏª¨ LLM(K-intelligence/Midm-2.0-Base-Instruct) Î°úÎìú ÏôÑÎ£å ---\n",
      "\n",
      "--- [INFO] ÌïòÏù¥Î∏åÎ¶¨Îìú RAG Ï≤¥Ïù∏ Íµ¨ÏÑ± ÏôÑÎ£å ---\n",
      "\n",
      "--- [CSV ÏÉùÏÑ± ÏãúÏûë] ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG Ï≤òÎ¶¨ Ï§ë:   0%|          | 0/2826 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacity of 23.55 GiB of which 779.75 MiB is free. Process 1491538 has 22.78 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 145.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(documents, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAG Ï≤òÎ¶¨ Ï§ë\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    104\u001b[0m     question \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏßàÎ¨∏: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m--> 105\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     results_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: question, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m: response\u001b[38;5;241m.\u001b[39mstrip()})\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/langchain_core/runnables/base.py:3049\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3048\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3049\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/langchain_core/language_models/llms.py:389\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    386\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    387\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    401\u001b[0m     )\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/langchain_core/language_models/llms.py:766\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    764\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    765\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/langchain_core/language_models/llms.py:971\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    969\u001b[0m         )\n\u001b[1;32m    970\u001b[0m     ]\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    979\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    980\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m    989\u001b[0m     ]\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    783\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 792\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    796\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    800\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/langchain_community/llms/huggingface_pipeline.py:285\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:321\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/pipelines/base.py:1439\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1436\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1437\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1438\u001b[0m     )\n\u001b[0;32m-> 1439\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/pipelines/base.py:1365\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1364\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1365\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1366\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:419\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    417\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 419\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[1;32m    422\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/generation/utils.py:2634\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2626\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2627\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2628\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2629\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2631\u001b[0m     )\n\u001b[1;32m   2633\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2634\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2647\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2648\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2649\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2650\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2651\u001b[0m     )\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/generation/utils.py:3615\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3612\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3615\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3616\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 959\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    961\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:474\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[1;32m    473\u001b[0m slice_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m-\u001b[39mlogits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[0;32m--> 474\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 170\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/accelerate/hooks.py:360\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    353\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    354\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    357\u001b[0m         ):\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 360\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    370\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    371\u001b[0m )\n",
      "File \u001b[0;32m/venv/main/lib/python3.12/site-packages/accelerate/utils/modeling.py:343\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map, non_blocking, clear_cache)\u001b[0m\n\u001b[1;32m    341\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 343\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.00 GiB. GPU 0 has a total capacity of 23.55 GiB of which 779.75 MiB is free. Process 1491538 has 22.78 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 145.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1Îã®Í≥Ñ: Î∂àÌïÑÏöîÌïú Î°úÍ∑∏ ÎπÑÌôúÏÑ±Ìôî ---\n",
    "# transformers ÎùºÏù¥Î∏åÎü¨Î¶¨Ïùò Ï†ïÎ≥¥ÏÑ± Î°úÍ∑∏Î•º ÎÅîÏúºÎ°úÏç® ÏµúÏ¢Ö Í≤∞Í≥ºÎßå ÍπîÎÅîÌïòÍ≤å Î≥º Ïàò ÏûàÎèÑÎ°ù ÏÑ§Ï†ï\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "\n",
    "# --- 2Îã®Í≥Ñ: Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Î∂ÑÌï† ---\n",
    "print(\"--- [INFO] Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Î∂ÑÌï† ÏãúÏûë ---\")\n",
    "loader = JSONLoader(\n",
    "    file_path=\"/workspace/2025-AI-Challeng-finance/cybersecurity_data_final_processed.jsonl\",\n",
    "    jq_schema='\"ÏßàÎ¨∏: \" + .question + \"\\\\nÎãµÎ≥Ä: \" + .answer',\n",
    "    json_lines=True,\n",
    "    text_content=False # page_contentÎßå Î°úÎìúÌïòÎèÑÎ°ù ÏÑ§Ï†ï\n",
    ")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "print(f\"--- [INFO] Î¨∏ÏÑúÍ∞Ä {len(split_docs)}Í∞úÏùò Ï≤≠ÌÅ¨Î°ú Î∂ÑÌï†ÎêòÏóàÏäµÎãàÎã§. ---\")\n",
    "\n",
    "\n",
    "# --- 3Îã®Í≥Ñ: ÌïòÏù¥Î∏åÎ¶¨Îìú Retriever ÏÉùÏÑ± ---\n",
    "\n",
    "# 1. ÌÇ§ÏõåÎìú Í∏∞Î∞ò Retriever ÏÉùÏÑ± (BM25)\n",
    "print(\"\\n--- [INFO] BM25 Retriever ÏÉùÏÑ± Ï§ë... ---\")\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# 2. ÏùòÎØ∏ Í∏∞Î∞ò Retriever ÏÉùÏÑ± (FAISS)\n",
    "print(\"\\n--- [INFO] FAISS Retriever ÏÉùÏÑ± Ï§ë... ---\")\n",
    "embedding_model_id = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_id)\n",
    "faiss_vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "# 3. Îëê RetrieverÎ•º EnsembleRetrieverÎ°ú Í≤∞Ìï©\n",
    "print(\"\\n--- [INFO] Ensemble RetrieverÎ°ú Îëê Î∞©Ïãù Í≤∞Ìï© Ï§ë... ---\")\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4Îã®Í≥Ñ: Î°úÏª¨ LLM Î°úÎìú Î∞è RAG Ï≤¥Ïù∏ ÏÉùÏÑ± ---\n",
    "print(f\"\\n--- [INFO] Î°úÏª¨ LLM Î°úÎìú Ï§ë... ---\")\n",
    "llm_model_id = \"K-intelligence/Midm-2.0-Base-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_model_id, torch_dtype=torch.bfloat16, device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512,\n",
    "    model_kwargs={\"temperature\": 0.1, \"repetition_penalty\": 1.1}\n",
    ")\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "print(f\"--- [INFO] Î°úÏª¨ LLM({llm_model_id}) Î°úÎìú ÏôÑÎ£å ---\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### [ÏßÄÏãú]\n",
    "Ï£ºÏñ¥ÏßÑ 'Í≤ÄÏÉâÎêú Ï†ïÎ≥¥'Î•º ÏÇ¨Ïö©ÌïòÏó¨ 'ÏßàÎ¨∏'Ïóê ÎåÄÌï¥ ÌïúÍµ≠Ïñ¥Î°ú ÏÉÅÏÑ∏ÌïòÍ≥† ÏπúÏ†àÌïòÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n",
    "### [Í≤ÄÏÉâÎêú Ï†ïÎ≥¥]\n",
    "{context}\n",
    "### [ÏßàÎ¨∏]\n",
    "{question}\n",
    "### [ÎãµÎ≥Ä]\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | local_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"\\n--- [INFO] ÌïòÏù¥Î∏åÎ¶¨Îìú RAG Ï≤¥Ïù∏ Íµ¨ÏÑ± ÏôÑÎ£å ---\")\n",
    "\n",
    "\n",
    "# --- 5Îã®Í≥Ñ: Î™®Îì† ÏßàÎ¨∏Ïóê ÎåÄÌï¥ ÎãµÎ≥Ä ÏÉùÏÑ± ÌõÑ CSVÎ°ú Ï†ÄÏû• ---\n",
    "print(\"\\n--- [CSV ÏÉùÏÑ± ÏãúÏûë] ---\")\n",
    "results_list = []\n",
    "output_filename = 'hybrid_rag_results.csv'\n",
    "fieldnames = ['question', 'answer']\n",
    "\n",
    "# tqdmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏßÑÌñâ ÏÉÅÌô©ÏùÑ ÌîÑÎ°úÍ∑∏Î†àÏä§ Î∞îÎ°ú ÌëúÏãú\n",
    "for doc in tqdm(documents, desc=\"RAG Ï≤òÎ¶¨ Ï§ë\"):\n",
    "    question = doc.page_content.split('\\n')[0].replace('ÏßàÎ¨∏: ', '').strip()\n",
    "    response = rag_chain.invoke(question)\n",
    "    results_list.append({'question': question, 'answer': response.strip()})\n",
    "\n",
    "with open(output_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results_list)\n",
    "\n",
    "print(f\"\\n--- [CSV ÏÉùÏÑ± ÏôÑÎ£å] ---\")\n",
    "print(f\"'{output_filename}' ÌååÏùºÏóê Î™®Îì† Í≤∞Í≥ºÍ∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a145c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
