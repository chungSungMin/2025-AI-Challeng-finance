{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf06b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ì´ 4ê°œì˜ íŒŒì¼ì„ ë³‘í•©í•©ë‹ˆë‹¤: ['/workspace/CyberMetric/CyberMetric-10000-v1.json', '/workspace/CyberMetric/CyberMetric-2000-v1.json', '/workspace/CyberMetric/CyberMetric-500-v1.json', '/workspace/CyberMetric/CyberMetric-80-v1.json']\n",
      "\n",
      "âœ… ë³‘í•©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ 12760ê°œì˜ ì§ˆë¬¸ì´ '/workspace/merged_questions.json' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def merge_json_files(input_pattern: str, output_filename: str):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  JSON íŒŒì¼ì„ ì°¾ì•„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "    :param input_pattern: ì°¾ì„ íŒŒì¼ì˜ íŒ¨í„´ (ì˜ˆ: 'data/*.json')\n",
    "    :param output_filename: ì €ì¥í•  ìµœì¢… íŒŒì¼ì˜ ì´ë¦„\n",
    "    \"\"\"\n",
    "    # 1. ë³‘í•©í•  JSON íŒŒì¼ ëª©ë¡ ì°¾ê¸°\n",
    "    json_files = glob.glob(input_pattern)\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: '{input_pattern}' íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“„ ì´ {len(json_files)}ê°œì˜ íŒŒì¼ì„ ë³‘í•©í•©ë‹ˆë‹¤: {json_files}\")\n",
    "\n",
    "    # 2. ëª¨ë“  'questions'ë¥¼ ë‹´ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    all_questions = []\n",
    "\n",
    "    # 3. ê° íŒŒì¼ì„ ìˆœíšŒí•˜ë©° 'questions' ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ê³  í•©ì¹˜ê¸°\n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # 'questions' í‚¤ê°€ ì¡´ì¬í•˜ê³ , ê·¸ ê°’ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°ì—ë§Œ ì¶”ê°€\n",
    "                if 'questions' in data and isinstance(data['questions'], list):\n",
    "                    all_questions.extend(data['questions'])\n",
    "                else:\n",
    "                    print(f\"âš ï¸ ê²½ê³ : '{file_path}' íŒŒì¼ì— 'questions' ë¦¬ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ë˜ì–´ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âš ï¸ ê²½ê³ : '{file_path}' íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"'{file_path}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "    # 4. ìµœì¢…ì ìœ¼ë¡œ í•©ì³ì§„ ë°ì´í„° êµ¬ì¡° ë§Œë“¤ê¸°\n",
    "    final_data = {\"questions\": all_questions}\n",
    "\n",
    "    # 5. ìƒˆë¡œìš´ JSON íŒŒì¼ì— ì €ì¥\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        # indent=4: ë³´ê¸° ì¢‹ê²Œ 4ì¹¸ ë“¤ì—¬ì“°ê¸° ì ìš©\n",
    "        # ensure_ascii=False: í•œê¸€ ë“± ë¹„-ASCII ë¬¸ìê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì •\n",
    "        json.dump(final_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nâœ… ë³‘í•©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ {len(all_questions)}ê°œì˜ ì§ˆë¬¸ì´ '{output_filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # â­ï¸ ì—¬ê¸°ì— ë³‘í•©í•  JSON íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œì™€ íŒŒì¼ íŒ¨í„´ì„ ì§€ì •í•˜ì„¸ìš”.\n",
    "    INPUT_PATTERN = '/workspace/CyberMetric/*.json' \n",
    "    \n",
    "    # â˜…â˜…â˜… ìˆ˜ì •ëœ ë¶€ë¶„: ì €ì¥ ê²½ë¡œë¥¼ /workspace/ë¡œ ëª…ì‹œ â˜…â˜…â˜…\n",
    "    OUTPUT_FILE = '/workspace/merged_questions.json'\n",
    "    \n",
    "    merge_json_files(INPUT_PATTERN, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b1310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12760\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "file_path = \"/workspace/merged_questions.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(len(dataset[\"questions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63f495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which of the following authentication factors involves something you know?', 'answer': 'Username'}\n"
     ]
    }
   ],
   "source": [
    "document_len = len(dataset[\"questions\"])\n",
    "real_data = dataset[\"questions\"]\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "for i in range(document_len):\n",
    "\n",
    "    question = real_data[i][\"question\"]\n",
    "    answer = real_data[i][\"answers\"].get(real_data[i][\"solution\"])\n",
    "\n",
    "    docs = {\n",
    "        \"question\" : question,\n",
    "        \"answer\" : answer\n",
    "    }\n",
    "\n",
    "    all_docs.append(docs)\n",
    "\n",
    "print(all_docs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbe4c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /venv/main/lib/python3.12/site-packages (4.55.0)\n",
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.8.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /venv/main/lib/python3.12/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/main/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /venv/main/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /venv/main/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /venv/main/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /venv/main/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /venv/main/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /venv/main/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /venv/main/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6050de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'facebook/nllb-200-distilled-600M' ë²ˆì—­ ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38497b2dcd6544abbfe5f01352939673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51479fba385c40f58904aa94c54819df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec908a552cb4880a14131cbf60b676b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a27c1628efb49dcbb5facfd1b636c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edc8b65dd104dc5aea408daff0cbb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5631384e731048d9948989b837325e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6451cb4c70440199d9ef38eabfb47e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c138fa7daf75454f83525838921ea066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë²ˆì—­ ëª¨ë¸ ë¡œë”© ì™„ë£Œ.\n",
      "\n",
      "ì´ 12760ê°œì˜ í•­ëª©ì— ëŒ€í•œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f408e06e31248aca7581d45e9bddbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ë²ˆì—­ ì§„í–‰ ì¤‘:   0%|          | 0/12760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- [ë²ˆì—­ ê²°ê³¼ ìƒ˜í”Œ] ---\n",
      "{\n",
      "  \"question\": \"ë‹¤ìŒ ì¤‘ ì–´ëŠ ê²ƒ ì€ ì •ë³´ ì˜ ë¹„ë°€ ì— ê´€í•œ ê²ƒ ì…ë‹ˆê¹Œ?\",\n",
      "  \"answer\": \"ë¹„ê³µê°œì„±\"\n",
      "}\n",
      "\n",
      "ğŸ’¾ ëª¨ë“  ë²ˆì—­ ê²°ê³¼ê°€ 'translated_qa_ko.jsonl' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "MODEL_NAME = \"facebook/nllb-200-distilled-600M\"\n",
    "OUTPUT_FILENAME = \"/workspace/translated_qa_ko.jsonl\"\n",
    "\n",
    "print(f\"'{MODEL_NAME}' ë²ˆì—­ ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ í›„ ì¥ì¹˜ ì„¤ì •\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# ë²ˆì—­ì„ ìœ„í•œ pipeline ê°ì²´ ìƒì„±\n",
    "translator = pipeline(\n",
    "    'translation',\n",
    "    model=MODEL_NAME,\n",
    "    tokenizer=MODEL_NAME,\n",
    "    src_lang='eng_Latn',  # ì†ŒìŠ¤ ì–¸ì–´: ì˜ì–´ (Latin script)\n",
    "    tgt_lang='kor_Hang',  # íƒ€ê²Ÿ ì–¸ì–´: í•œêµ­ì–´ (Hangul script)\n",
    "    device=device         # GPUê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ CPU(-1) ì‚¬ìš©\n",
    ")\n",
    "\n",
    "print(\"âœ… ë²ˆì—­ ëª¨ë¸ ë¡œë”© ì™„ë£Œ.\")\n",
    "\n",
    "# --- 3. ë°ì´í„° ë²ˆì—­ ì‹¤í–‰ ---\n",
    "\n",
    "# ë²ˆì—­ëœ ê²°ê³¼ë¥¼ ì €ì¥í•  ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸\n",
    "translated_docs = []\n",
    "\n",
    "print(f\"\\nì´ {len(all_docs)}ê°œì˜ í•­ëª©ì— ëŒ€í•œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ\n",
    "for doc in tqdm(all_docs, desc=\"ë²ˆì—­ ì§„í–‰ ì¤‘\"):\n",
    "    # ì§ˆë¬¸ê³¼ ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ í•œ ë²ˆì— ë²ˆì—­ (ë” íš¨ìœ¨ì )\n",
    "    texts_to_translate = [\n",
    "        doc.get(\"question\", \"\"),\n",
    "        doc.get(\"answer\", \"\")\n",
    "    ]\n",
    "    \n",
    "    # ë²ˆì—­ ì‹¤í–‰\n",
    "    translation_results = translator(texts_to_translate, max_length=512)\n",
    "    \n",
    "    # ë²ˆì—­ ê²°ê³¼ ì¶”ì¶œ\n",
    "    translated_question = translation_results[0]['translation_text']\n",
    "    translated_answer = translation_results[1]['translation_text']\n",
    "    \n",
    "    # ë²ˆì—­ëœ ë‚´ìš©ìœ¼ë¡œ ìƒˆë¡œìš´ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "    translated_doc = {\n",
    "        \"question\": translated_question,\n",
    "        \"answer\": translated_answer\n",
    "    }\n",
    "    \n",
    "    # ìµœì¢… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    translated_docs.append(translated_doc)\n",
    "\n",
    "print(\"\\nâœ… ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# --- 4. ë²ˆì—­ ê²°ê³¼ í™•ì¸ ë° íŒŒì¼ ì €ì¥ ---\n",
    "\n",
    "print(\"\\n--- [ë²ˆì—­ ê²°ê³¼ ìƒ˜í”Œ] ---\")\n",
    "print(json.dumps(translated_docs[0], indent=2, ensure_ascii=False))\n",
    "\n",
    "# ë²ˆì—­ëœ ì „ì²´ ê²°ê³¼ë¥¼ jsonl íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "    for doc in translated_docs:\n",
    "        # ê° ë”•ì…”ë„ˆë¦¬ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ì— í•œ ì¤„ì”© ì”€\n",
    "        f.write(json.dumps(doc, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"\\nğŸ’¾ ëª¨ë“  ë²ˆì—­ ê²°ê³¼ê°€ '{OUTPUT_FILENAME}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ëª¨ë“  ë²ˆì—­ ê²°ê³¼ê°€ '/workspace/translated_qa_ko.jsonl' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "# ë²ˆì—­ëœ ì „ì²´ ê²°ê³¼ë¥¼ jsonl íŒŒì¼ë¡œ ì €ì¥\n",
    "OUTPUT_FILENAME = \"/workspace/translated_qa_ko.jsonl\"\n",
    "\n",
    "\n",
    "with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "    for doc in translated_docs:\n",
    "        # ê° ë”•ì…”ë„ˆë¦¬ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ì— í•œ ì¤„ì”© ì”€\n",
    "        f.write(json.dumps(doc, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"\\nğŸ’¾ ëª¨ë“  ë²ˆì—­ ê²°ê³¼ê°€ '{OUTPUT_FILENAME}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a213a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
