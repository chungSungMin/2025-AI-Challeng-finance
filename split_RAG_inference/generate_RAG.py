# generate_RAG.py

import os
from tqdm import tqdm
# from datasets import load_dataset  # ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì‚­ì œí•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬

# PDF ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ë¶„í• ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from pypdf import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

# --- ì„¤ì • (Configuration) ---
# ğŸ“„ ì´ì œ JSONLì´ ì•„ë‹Œ PDF íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
RAG_DATA_FILES = [
    "/workspace/2025-AI-Challeng-finance/á„€á…¢á„‹á…µá†«á„€á…³á†·á„‹á…²á†¼á„á…¢á„€á…¯á†«á„‹á…´ á„€á…ªá†«á„…á…µ á„†á…µá†¾ á„€á…¢á„‹á…µá†«á„€á…³á†·á„‹á…²á†¼á„á…¢á„†á…®á„Œá…¡á„‹á…´ á„‡á…©á„’á…©á„‹á…¦ á„€á…ªá†«á„’á…¡á†« á„‡á…¥á†¸á„…á…²á†¯(á„‡á…¥á†¸á„…á…²á†¯)(á„Œá…¦20369á„’á…©)(20241017).pdf",
"/workspace/2025-AI-Challeng-finance/á„€á…¢á„‹á…µá†«á„Œá…¥á†¼á„‡á…© á„‡á…©á„’á…©á„‡á…¥á†¸(á„‡á…¥á†¸á„…á…²á†¯)(á„Œá…¦19234á„’á…©)(20250313) (1).pdf",
"/workspace/2025-AI-Challeng-finance/á„€á…¥á„‡á…¥á„‚á…¥á†«á„‰á…³.pdf",
"/workspace/2025-AI-Challeng-finance/á„€á…§á†¼á„á…¡á†¯á„€á…©á†¼á„†á…®á„‹á…¯á†« á„ƒá…³á†¼á„‹á…´ á„€á…¢á„‹á…µá†«á„Œá…¥á†¼á„‡á…© á„á…¥á„…á…µá„‹á…¦ á„€á…ªá†«á„’á…¡á†« á„€á…²á„Œá…¥á†¼(á„ƒá…¢á„á…©á†¼á„…á…§á†¼á„…á…§á†¼)(á„Œá…¦35039á„’á…©)(20241203).pdf",
"/workspace/2025-AI-Challeng-finance/á„€á…³á†·á„‹á…²á†¼á„‡á…©á„‹á…¡á†«á„‹á…§á†«á„€á…®á„‹á…¯á†«.pdf",
"/workspace/2025-AI-Challeng-finance/á„€á…³á†·á„‹á…²á†¼á„‰á…©á„‡á…µá„Œá…¡ á„‡á…©á„’á…©á„‹á…¦ á„€á…ªá†«á„’á…¡á†« á„‡á…¥á†¸á„…á…²á†¯(á„‡á…¥á†¸á„…á…²á†¯)(á„Œá…¦20305á„’á…©)(20240814).pdf",
"/workspace/2025-AI-Challeng-finance/á„€á…³á†·á„‹á…²á†¼á„‰á…µá†¯á„†á…§á†¼á„€á…¥á„…á…¢ á„†á…µá†¾ á„‡á…µá„†á…µá†¯á„‡á…©á„Œá…¡á†¼á„‹á…¦ á„€á…ªá†«á„’á…¡á†« á„‡á…¥á†¸á„…á…²á†¯ á„‰á…µá„’á…¢á†¼á„€á…²á„á…µá†¨(á„á…©á†¼á„…á…µá„…á…§á†¼)(á„Œá…¦01406á„’á…©)(20170726).pdf",
"/workspace/2025-AI-Challeng-finance/á„…á…¢á†«á„‰á…¥á†·á„‹á…°á„‹á…¥.pdf",
"/workspace/2025-AI-Challeng-finance/á„†á…¡á„‹á…µá„ƒá…¦á„‹á…µá„á…¥.pdf",
"/workspace/2025-AI-Challeng-finance/á„†á…¦á„á…¡á„‡á…¥á„‰á…³.pdf",
"/workspace/2025-AI-Challeng-finance/á„‡á…¥á†¸á„‹á…¯á†« á„€á…¢á„‹á…µá†«á„Œá…¥á†¼á„‡á…© á„‡á…©á„’á…©á„‹á…¦ á„€á…ªá†«á„’á…¡á†« á„€á…²á„á…µá†¨(á„ƒá…¢á„‡á…¥á†¸á„‹á…¯á†«á„€á…²á„á…µá†¨)(á„Œá…¦03109á„’á…©)(20240315).pdf",
"/workspace/2025-AI-Challeng-finance/á„‹á…¡á„‹á…®á†ºá„‰á…©á„‰á…µá†¼.pdf",
"/workspace/2025-AI-Challeng-finance/á„Œá…¥á†¼á„‡á…©_á„‡á…©á„‹á…¡á†«.pdf",
"/workspace/2025-AI-Challeng-finance/á„á…³á†¯á„…á…¡á„‹á…®á„ƒá…³á„á…¥á†·á„‘á…²á„á…µá†¼ á„‡á…¡á†¯á„Œá…¥á†« á„†á…µá†¾ á„‹á…µá„‹á…­á†¼á„Œá…¡ á„‡á…©á„’á…©á„‹á…¦ á„€á…ªá†«á„’á…¡á†« á„‡á…¥á†¸á„…á…²á†¯(á„‡á…¥á†¸á„…á…²á†¯)(á„Œá…¦20732á„’á…©)(20250131).pdf",
]
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"
FAISS_DB_PATH = "./faiss_index_laws"


# â­ï¸ PDFë¥¼ ì½ê³  í…ìŠ¤íŠ¸ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜ (ìƒˆë¡œ ì¶”ê°€)
def load_and_chunk_pdfs(file_paths):
    all_docs = []
    for file_path in file_paths:
        print(f"ğŸ“„ '{os.path.basename(file_path)}' íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
        # 1. PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        reader = PdfReader(file_path)
        raw_text = ""
        for page in reader.pages:
            raw_text += page.extract_text() if page.extract_text() else ""

        # 2. ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í•  (Chunking)
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, # ì²­í¬ í¬ê¸°
            chunk_overlap=100, # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„
            separators=["\n\n", "\n", " ", ""],
        )
        chunks = text_splitter.split_text(raw_text)

        # 3. ë¶„í• ëœ ì²­í¬ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
        for chunk in chunks:
            all_docs.append(Document(page_content=chunk, metadata={"source": os.path.basename(file_path)}))
    
    print(f"âœ… ì´ {len(all_docs)}ê°œì˜ ë¬¸ì„œ(chunk)ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    return all_docs


# â­ï¸ PDF ì²˜ë¦¬ ë¡œì§ì„ ì ìš©í•œ DB ìƒì„± í•¨ìˆ˜ (ìˆ˜ì •)
def create_and_save_vector_db():
    """
    PDF íŒŒì¼ë“¤ì„ ì½ê³  ì²˜ë¦¬í•˜ì—¬ FAISS ë²¡í„° DBë¥¼ ìƒì„±í•˜ê³  ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    print(f"ğŸš€ ì„ë² ë”© ëª¨ë¸({EMBEDDING_MODEL_NAME})ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        encode_kwargs={'normalize_embeddings': True}
    )
    print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    # 2. PDF ë¡œë“œ ë° ì²˜ë¦¬ (load_dataset ëŒ€ì‹  ìƒˆë¡œ ë§Œë“  í•¨ìˆ˜ ì‚¬ìš©)
    documents = load_and_chunk_pdfs(RAG_DATA_FILES)
    
    # 3. FAISS ë²¡í„° DB ìƒì„±
    print("ğŸ§  FAISS ë²¡í„° DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
    vector_db = FAISS.from_documents(documents, embedding_model)
    
    # 4. ìƒì„±ëœ DBë¥¼ ë¡œì»¬ì— ì €ì¥
    vector_db.save_local(FAISS_DB_PATH)
    print(f"âœ… ìƒˆë¡œìš´ ë²¡í„° DB êµ¬ì¶• ë° ì €ì¥ ì™„ë£Œ: '{FAISS_DB_PATH}'")


if __name__ == "__main__":
    if os.path.exists(FAISS_DB_PATH):
        print(f"âš ï¸ ê²½ê³ : '{FAISS_DB_PATH}'ì— ì´ë¯¸ DBê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        user_input = input("ê¸°ì¡´ DBë¥¼ ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
        if user_input == 'y':
            create_and_save_vector_db()
        else:
            print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
    else:
        create_and_save_vector_db()